"""
æ‰‹è¯­è¯†åˆ«ç‰¹å¾æå–è„šæœ¬
è¯¥è„šæœ¬ç”¨äºä»æ‰‹è¯­å›¾ç‰‡ä¸­æ‰¹é‡æå–æ‰‹éƒ¨ç‰¹å¾ï¼Œå¹¶å°†å…¶ä¿å­˜ä¸ºNumPyæ•°ç»„æ ¼å¼
ä¸»è¦åŠŸèƒ½ï¼š
1. ä½¿ç”¨MediaPipeä»å›¾ç‰‡ä¸­æå–æ‰‹éƒ¨å…³é”®ç‚¹
2. å°†å…³é”®ç‚¹åæ ‡è½¬æ¢ä¸ºç‰¹å¾å‘é‡
3. ä¿å­˜ç‰¹å¾å‘é‡å’Œå¯¹åº”çš„æ ‡ç­¾
"""

import cv2
import mediapipe as mp
import os
import numpy as np
from tqdm import tqdm

# é…ç½®TensorFlowæ—¥å¿—çº§åˆ«ï¼Œå‡å°‘ä¸å¿…è¦çš„è­¦å‘Š
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# é…ç½®æ–‡ä»¶è·¯å¾„
IMAGE_DIR = 'data/train'  # è®­ç»ƒå›¾ç‰‡ç›®å½•
OUTPUT_DIR = 'data/processed'  # è¾“å‡ºç›®å½•
FEATURES_FILE = os.path.join(OUTPUT_DIR, 'features.npy')  # ç‰¹å¾æ–‡ä»¶
LABELS_FILE = os.path.join(OUTPUT_DIR, 'labels.npy')  # æ ‡ç­¾æ–‡ä»¶

def extract_hand_features(image_path, hands_detector):
    """
    ä»å•ä¸ªå›¾åƒä¸­æå–æ‰‹éƒ¨ç‰¹å¾
    
    å‚æ•°:
        image_path: è¾“å…¥å›¾åƒçš„è·¯å¾„
        hands_detector: MediaPipe Hands æ£€æµ‹å™¨å®ä¾‹
    
    è¿”å›:
        numpy.ndarray: 63ç»´ç‰¹å¾å‘é‡ï¼ˆ21ä¸ªå…³é”®ç‚¹ * 3ä¸ªåæ ‡ï¼‰ï¼Œå¦‚æœæœªæ£€æµ‹åˆ°æ‰‹åˆ™è¿”å›None
    """
    # è¯»å–å›¾åƒ
    image = cv2.imread(image_path)
    if image is None:
        return None
    
    # è½¬æ¢åˆ°RGBé¢œè‰²ç©ºé—´ï¼ˆMediaPipeè¦æ±‚ï¼‰
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    # å¤„ç†å›¾åƒï¼Œæ£€æµ‹æ‰‹éƒ¨å…³é”®ç‚¹
    results = hands_detector.process(image_rgb)
    
    # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°æ‰‹ï¼Œè¿”å›None
    if not results.multi_hand_landmarks:
        return None
    
    # æå–ç¬¬ä¸€åªæ‰‹çš„æ‰€æœ‰å…³é”®ç‚¹
    hand_landmarks = results.multi_hand_landmarks[0]
    
    # å°†21ä¸ªå…³é”®ç‚¹çš„x,y,zåæ ‡å±•å¹³ä¸ºä¸€ç»´å‘é‡
    # æ¯ä¸ªå…³é”®ç‚¹æœ‰3ä¸ªåæ ‡ï¼Œå…±63ç»´
    features = np.array([[lm.x, lm.y, lm.z] 
                        for lm in hand_landmarks.landmark]).flatten()
    return features

def main():
    """
    ä¸»å‡½æ•°ï¼šæ‰¹é‡å¤„ç†å›¾åƒå¹¶ä¿å­˜ç‰¹å¾
    """
    print("=== å¼€å§‹æå–æ‰‹éƒ¨ç‰¹å¾ ===")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # åˆå§‹åŒ–MediaPipe Handsæ£€æµ‹å™¨
    mp_hands = mp.solutions.hands
    hands_detector = mp_hands.Hands(
        static_image_mode=True,    # é™æ€å›¾ç‰‡æ¨¡å¼
        max_num_hands=1,           # æœ€å¤šæ£€æµ‹ä¸€åªæ‰‹
        min_detection_confidence=0.3  # æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼
    )
    
    # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
    image_files = [f for f in os.listdir(IMAGE_DIR) 
                  if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    
    if not image_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å›¾åƒæ–‡ä»¶ï¼")
        return
    
    # å­˜å‚¨æå–çš„ç‰¹å¾å’Œæ ‡ç­¾
    features_list = []
    labels_list = []
    
    # å¤„ç†æ¯ä¸ªå›¾åƒ
    print("ğŸ“¸ æ­£åœ¨å¤„ç†å›¾åƒ...")
    with hands_detector:
        for filename in tqdm(image_files, desc="å¤„ç†è¿›åº¦"):
            filepath = os.path.join(IMAGE_DIR, filename)
            
            # æå–ç‰¹å¾
            features = extract_hand_features(filepath, hands_detector)
            
            if features is not None:
                features_list.append(features)
                # ä»æ–‡ä»¶åè·å–æ ‡ç­¾ï¼ˆç¬¬ä¸€ä¸ªå­—ç¬¦ï¼‰
                label = filename[0].upper()
                labels_list.append(label)
    
    if not features_list:
        print("âŒ æ²¡æœ‰æˆåŠŸæå–åˆ°ä»»ä½•ç‰¹å¾ï¼")
        return
    
    # è½¬æ¢ä¸ºNumPyæ•°ç»„
    features_array = np.array(features_list)
    labels_array = np.array(labels_list)
    
    # ä¿å­˜ç‰¹å¾å’Œæ ‡ç­¾
    np.save(FEATURES_FILE, features_array)
    np.save(LABELS_FILE, labels_array)
    
    print("\n=== æå–å®Œæˆ ===")
    print(f"âœ… æˆåŠŸæå–ç‰¹å¾: {len(features_list)} ä¸ªæ ·æœ¬")
    print(f"âœ… ç‰¹å¾ç»´åº¦: {features_array.shape}")
    print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {OUTPUT_DIR}")

if __name__ == "__main__":
    main()