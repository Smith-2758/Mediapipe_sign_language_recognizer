import cv2
import mediapipe as mp
import os
import csv
import numpy as np
from tqdm import tqdm
# landmark_pb2 ç”¨äºæ„å»ºç»˜åˆ¶æ‰€éœ€çš„æ•°æ®ç»“æ„
from mediapipe.framework.formats import landmark_pb2

# === å¯è§†åŒ–å‡½æ•° (ä¿æŒä½ çš„å‡½æ•°ç»“æ„ï¼Œç¨ä½œå¥å£®æ€§è°ƒæ•´) ===
MARGIN = 10  # æ–‡æœ¬è¾¹è·
FONT_SIZE = 1
FONT_THICKNESS = 1
HANDEDNESS_TEXT_COLOR = (88, 205, 54)  # BGR ç»¿è‰²

def draw_landmarks_on_image(rgb_image, detection_result):
    """åœ¨å›¾åƒä¸Šç»˜åˆ¶æ‰‹éƒ¨å…³é”®ç‚¹å’Œå·¦å³æ‰‹æ ‡ç­¾"""
    hand_landmarks_list = detection_result.multi_hand_landmarks
    handedness_list = detection_result.multi_handedness
    # åˆ›å»ºå›¾åƒå‰¯æœ¬è¿›è¡Œç»˜åˆ¶ï¼Œé¿å…ä¿®æ”¹åŸå§‹å›¾åƒ
    annotated_image = np.copy(rgb_image)

    # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°æ‰‹ï¼Œç›´æ¥è¿”å›åŸå›¾å‰¯æœ¬
    if not hand_landmarks_list:
        return annotated_image

    # éå†æ£€æµ‹åˆ°çš„æ¯ä¸€åªæ‰‹
    for idx in range(len(hand_landmarks_list)):
        hand_landmarks = hand_landmarks_list[idx]
        handedness = None
        # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„å·¦å³æ‰‹ä¿¡æ¯
        if handedness_list and idx < len(handedness_list):
             handedness = handedness_list[idx]

        # --- ç»˜åˆ¶å…³é”®ç‚¹å’Œè¿æ¥çº¿ ---
        # éœ€è¦å°† landmark åˆ—è¡¨è½¬æ¢ä¸º MediaPipe å®šä¹‰çš„ NormalizedLandmarkList æ ¼å¼
        hand_landmarks_proto = landmark_pb2.NormalizedLandmarkList()
        hand_landmarks_proto.landmark.extend([
            landmark_pb2.NormalizedLandmark(x=lm.x, y=lm.y, z=lm.z) for lm in hand_landmarks.landmark
        ])

        mp.solutions.drawing_utils.draw_landmarks(
            image=annotated_image,                   # åœ¨å“ªä¸ªå›¾åƒä¸Šç»˜åˆ¶
            landmark_list=hand_landmarks_proto,      # å…³é”®ç‚¹æ•°æ®
            connections=mp.solutions.hands.HAND_CONNECTIONS, # å¦‚ä½•è¿æ¥å…³é”®ç‚¹
            landmark_drawing_spec=mp.solutions.drawing_styles.get_default_hand_landmarks_style(), # å…³é”®ç‚¹æ ·å¼
            connection_drawing_spec=mp.solutions.drawing_styles.get_default_hand_connections_style() # è¿æ¥çº¿æ ·å¼
        )

        # --- ç»˜åˆ¶å·¦å³æ‰‹æ ‡ç­¾ (å¦‚æœä¿¡æ¯å¯ç”¨) ---
        if handedness:
            h, w, _ = annotated_image.shape
            # è·å–æ‰‹éƒ¨è¾¹ç•Œç”¨äºå®šä½æ–‡æœ¬
            x_coords = [lm.x for lm in hand_landmarks.landmark]
            y_coords = [lm.y for lm in hand_landmarks.landmark]

            # ç¡®ä¿åæ ‡åˆ—è¡¨ä¸ä¸ºç©ºå†è®¡ç®— min
            if x_coords and y_coords:
                text_x = int(min(x_coords) * w)
                text_y = int(min(y_coords) * h) - MARGIN # å°†æ–‡æœ¬æ”¾åœ¨æ‰‹éƒ¨ä¸Šæ–¹

                cv2.putText(annotated_image, f"{handedness.classification[0].label}", # è·å– 'Left' æˆ– 'Right'
                            (text_x, text_y), cv2.FONT_HERSHEY_DUPLEX,
                            FONT_SIZE, HANDEDNESS_TEXT_COLOR, FONT_THICKNESS, cv2.LINE_AA)

    # è¿”å›å¸¦æœ‰æ ‡æ³¨çš„å›¾åƒ (RGBæ ¼å¼)
    return annotated_image

# === ä¸»ç¨‹åº ===
# è®¾ç½® TensorFlow æ—¥å¿—çº§åˆ« (å¯é€‰ï¼Œå‡å°‘æ— å…³ä¿¡æ¯)
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# --- é…ç½®è·¯å¾„ ---
IMAGE_DIR = 'data/test'  # åŒ…å«è®­ç»ƒå›¾ç‰‡çš„ç›®å½•
OUTPUT_CSV = 'data/raw/hand_data.csv'  # è¾“å‡º CSV æ–‡ä»¶è·¯å¾„

# --- æ‰“å°é…ç½®ä¿¡æ¯ ---
print("--- é…ç½®ä¿¡æ¯ ---")
print(f"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
print(f"å›¾ç‰‡ç›®å½• (ç»å¯¹è·¯å¾„): {os.path.abspath(IMAGE_DIR)}")
print(f"è¾“å‡ºCSVæ–‡ä»¶ (ç»å¯¹è·¯å¾„): {os.path.abspath(OUTPUT_CSV)}")

# --- æ£€æŸ¥è¾“å…¥ç›®å½• ---
if not os.path.isdir(IMAGE_DIR):
    print(f"\né”™è¯¯: å›¾ç‰‡ç›®å½•ä¸å­˜åœ¨: {os.path.abspath(IMAGE_DIR)}")
    print("è¯·ç¡®ä¿è·¯å¾„æ­£ç¡®æˆ–ç›®å½•å·²åˆ›å»ºã€‚")
    exit() # é€€å‡ºç¨‹åº

# --- å‡†å¤‡è¾“å‡ºç›®å½• ---
output_dir = os.path.dirname(OUTPUT_CSV)
# å¦‚æœ OUTPUT_CSV åŒ…å«ç›®å½•éƒ¨åˆ†ï¼Œåˆ™åˆ›å»ºå®ƒ
if output_dir and not os.path.exists(output_dir):
    os.makedirs(output_dir, exist_ok=True)
    print(f"è¾“å‡ºç›®å½•å·²åˆ›å»º: {os.path.abspath(output_dir)}")
elif output_dir:
     print(f"è¾“å‡ºç›®å½•å·²å­˜åœ¨: {os.path.abspath(output_dir)}")

# --- è·å–å›¾ç‰‡æ–‡ä»¶åˆ—è¡¨ ---
try:
    image_files = [f for f in os.listdir(IMAGE_DIR) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    if not image_files:
        print(f"\nè­¦å‘Š: åœ¨ç›®å½• '{os.path.abspath(IMAGE_DIR)}' ä¸­æœªæ‰¾åˆ°ä»»ä½•å›¾ç‰‡æ–‡ä»¶ (.png, .jpg, .jpeg)ã€‚")
        exit()
    print(f"âœ… åœ¨å›¾ç‰‡ç›®å½•ä¸­æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡ã€‚")
except FileNotFoundError:
    print(f"\né”™è¯¯: è®¿é—®å›¾ç‰‡ç›®å½•æ—¶å‡ºé”™: {os.path.abspath(IMAGE_DIR)}")
    exit()
except Exception as e:
     print(f"\né”™è¯¯: è¯»å–å›¾ç‰‡ç›®å½•æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
     exit()

# --- åˆå§‹åŒ– MediaPipe Hands ---
mp_hands = mp.solutions.hands
# ä½¿ç”¨ 'with' è¯­å¥ç¡®ä¿èµ„æºæ­£ç¡®ç®¡ç†
hands_detector = mp_hands.Hands(
    static_image_mode=True,       # é€‚ç”¨äºé™æ€å›¾ç‰‡
    max_num_hands=1,              # æœ€å¤šæ£€æµ‹ä¸€åªæ‰‹ (æ ¹æ®ä½ çš„è®¾ç½®)
    min_detection_confidence=0.3, # æœ€ä½æ£€æµ‹ç½®ä¿¡åº¦ (æ ¹æ®ä½ çš„è®¾ç½®)
    model_complexity=1            # æ¨¡å‹å¤æ‚åº¦ (æ ¹æ®ä½ çš„è®¾ç½®, 0 æˆ– 1)
)

# --- å¤„ç†å›¾ç‰‡å¹¶å†™å…¥ CSV ---
print("\n--- å¼€å§‹å¤„ç†å›¾åƒå¹¶æå–å…³é”®ç‚¹ ---")
success_count = 0
failed_count = 0

try:
    # æ‰“å¼€ CSV æ–‡ä»¶å‡†å¤‡å†™å…¥
    with open(OUTPUT_CSV, mode='w', newline='', encoding='utf-8') as csv_file:
        writer = csv.writer(csv_file)

        # å†™å…¥ CSV æ–‡ä»¶çš„è¡¨å¤´
        header = []
        for i in range(21):  # MediaPipe æä¾› 21 ä¸ªæ‰‹éƒ¨å…³é”®ç‚¹
            header.extend([f'x{i}', f'y{i}', f'z{i}']) # x, y, z åæ ‡
        header.append('label') # æ·»åŠ æ ‡ç­¾åˆ—
        writer.writerow(header)

        # ä½¿ç”¨ MediaPipe Hands å¯¹è±¡å¤„ç†å›¾ç‰‡
        with hands_detector:
            # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦æ¡
            for filename in tqdm(image_files, desc="å¤„ç†è¿›åº¦", unit="å¼ "):
                filepath = os.path.join(IMAGE_DIR, filename)

                # 1. è¯»å–å›¾ç‰‡
                image = cv2.imread(filepath)
                if image is None:
                    tqdm.write(f"âš ï¸ è­¦å‘Š: æ— æ³•è¯»å–å›¾åƒæ–‡ä»¶: {filename}") # ä½¿ç”¨ tqdm.write é¿å…ç ´åè¿›åº¦æ¡
                    failed_count += 1
                    continue # è·³è¿‡è¿™ä¸ªæ–‡ä»¶

                # 2. è½¬æ¢é¢œè‰²ç©ºé—´ (OpenCV: BGR -> MediaPipe: RGB)
                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

                # 3. ä½¿ç”¨ MediaPipe å¤„ç†å›¾åƒ
                try:
                    results = hands_detector.process(image_rgb)
                except Exception as e:
                    tqdm.write(f"âŒ é”™è¯¯: å¤„ç†å›¾åƒ {filename} æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
                    failed_count += 1
                    continue # è·³è¿‡è¿™ä¸ªæ–‡ä»¶

                # 4. æ£€æŸ¥æ˜¯å¦æ£€æµ‹åˆ°æ‰‹éƒ¨å…³é”®ç‚¹
                if results.multi_hand_landmarks:
                    # å› ä¸ºè®¾ç½®äº† max_num_hands=1ï¼Œæ‰€ä»¥æˆ‘ä»¬åªå–ç¬¬ä¸€ä¸ªæ£€æµ‹åˆ°çš„æ‰‹
                    hand_landmarks = results.multi_hand_landmarks[0]

                    # 5. æå–åæ ‡å¹¶å‡†å¤‡å†™å…¥ CSV çš„è¡Œæ•°æ®
                    row_data = []
                    for lm in hand_landmarks.landmark:
                        # æå–å½’ä¸€åŒ–çš„ x, y, z åæ ‡
                        row_data.extend([lm.x, lm.y, lm.z])

                    # 6. ä»æ–‡ä»¶åè·å–æ ‡ç­¾ (å‡è®¾æ ‡ç­¾æ˜¯æ–‡ä»¶åçš„ç¬¬ä¸€ä¸ªå­—ç¬¦)
                    label = filename[0].upper()
                    row_data.append(label)

                    # 7. å†™å…¥ CSV æ–‡ä»¶
                    writer.writerow(row_data)
                    success_count += 1

                    # --- å¯é€‰: å¯è§†åŒ–å¹¶ä¿å­˜/æ˜¾ç¤ºæ ‡æ³¨å›¾åƒ ---
                    # annotated_image_rgb = draw_landmarks_on_image(image_rgb, results)
                    # # è½¬å› BGR ä»¥ä¾¿ OpenCV æ˜¾ç¤ºæˆ–ä¿å­˜
                    # annotated_image_bgr = cv2.cvtColor(annotated_image_rgb, cv2.COLOR_RGB2BGR)
                    #
                    # # åˆ›å»ºç”¨äºä¿å­˜æ ‡æ³¨å›¾åƒçš„ç›®å½• (å¦‚æœéœ€è¦)
                    # annotated_output_dir = os.path.join(os.path.dirname(OUTPUT_CSV), 'annotated_images')
                    # os.makedirs(annotated_output_dir, exist_ok=True)
                    # annotated_filepath = os.path.join(annotated_output_dir, f"annotated_{filename}")
                    # cv2.imwrite(annotated_filepath, annotated_image_bgr)
                    #
                    # # æˆ–è€…å®æ—¶æ˜¾ç¤º (æŒ‰ä»»æ„é”®ç»§ç»­)
                    # # cv2.imshow("Annotated Image", annotated_image_bgr)
                    # # cv2.waitKey(1) # æ˜¾ç¤ºéå¸¸çŸ­çš„æ—¶é—´ï¼Œæˆ–è€…ç”¨ 0 ç­‰å¾…æŒ‰é”®
                    # --- å¯è§†åŒ–ç»“æŸ ---

                else:
                    # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°æ‰‹éƒ¨ï¼Œå¢åŠ å¤±è´¥è®¡æ•°
                    tqdm.write(f"â„¹ï¸ ä¿¡æ¯: åœ¨å›¾åƒ {filename} ä¸­æœªæ£€æµ‹åˆ°æ‰‹éƒ¨ã€‚") # å¯é€‰æç¤º
                    failed_count += 1

    # å¯é€‰ï¼šå¦‚æœåœ¨å¾ªç¯ä¸­ä½¿ç”¨äº† cv2.imshow, åœ¨è¿™é‡Œå…³é—­æ‰€æœ‰çª—å£
    # cv2.destroyAllWindows()

except IOError as e:
    print(f"\nâŒ é”™è¯¯: æ— æ³•æ‰“å¼€æˆ–å†™å…¥ CSV æ–‡ä»¶ '{OUTPUT_CSV}': {e}")
    print("è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„å’Œå†™å…¥æƒé™ã€‚")
except Exception as e:
    print(f"\nâŒ é”™è¯¯: å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿæœªé¢„æ–™çš„é”™è¯¯: {e}")

# --- è¾“å‡ºæœ€ç»ˆç»“æœ ---
print("\n--- å¤„ç†å®Œæˆ ---")
print(f"âœ”ï¸ æˆåŠŸæå–å¹¶ä¿å­˜å…³é”®ç‚¹: {success_count} å¼ å›¾åƒ")
print(f"âŒ æœªæ£€æµ‹åˆ°æ‰‹éƒ¨æˆ–å¤„ç†å¤±è´¥: {failed_count} å¼ å›¾åƒ")
if success_count > 0:
    print(f"ğŸ“„ æ•°æ®å·²ä¿å­˜åˆ°: {os.path.abspath(OUTPUT_CSV)}")
elif failed_count == len(image_files) and len(image_files) > 0:
     print("âš ï¸ æ‰€æœ‰å›¾åƒå‡æœªèƒ½æ£€æµ‹åˆ°æ‰‹éƒ¨ã€‚è¯·æ£€æŸ¥ï¼š")
     print("   - å›¾ç‰‡è´¨é‡å’Œå†…å®¹ (æ‰‹éƒ¨æ˜¯å¦æ¸…æ™°å¯è§ï¼Ÿ)")
     print(f"   - MediaPipe å‚æ•° (min_detection_confidence={hands_detector.min_detection_confidence}) æ˜¯å¦åˆé€‚ï¼Ÿ")
elif not image_files:
     print("ç›®å½•ä¸­æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å›¾ç‰‡æ–‡ä»¶ã€‚")